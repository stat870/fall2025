# Planning designed experiments 

## Announcements 

- Project deadlines:
  - **December 12th:** give your presentation by this date (it can be earlier than this also). You will need to schedule a 30min meeting with me. 
  - **December 19th:** submit your final project and tutorial on canvas, including both your classmate's and my feedback.

## Designed experiments 

- On the importace of designed experiments 
- Defining the data generating process 
- Statistical power 
- Precision of parameters 

```{r echo=FALSE, fig.cap="Types of errors.", out.width = '80%', fig.align='center'}
knitr::include_graphics("../figures/error_types.jpg")
```

#### Analytical solutions 
We know Power is  

$$Power = P(F>F_{c} \vert F \sim F(df_1, df_2, \phi)),$$

where: 

- $F$ is the F test statistics, 
- $F_c$ is the critical test F, 
- $df_1$ are the degrees of freedom of the numerator, 
- $df_2$ are the degrees of freedom of the denominator, 
- $\phi$ is the noncentrality parameter. 

Note that $F$ depends on $\sigma^2_\varepsilon$, and $F_c$ depends on $\alpha$.

Suppose we are trying to compare designs to find differences main effects and interactions of a $2 \times 2$ factorial treatment structure. 
Suppose we have: 

- Treatment A: 3 levels, 
- Treatment B: 2 levels. 

Typically, we would find means around $10$ units, and $\sigma^2 \approx 1$. 

```{r message=FALSE, warning=FALSE}
library(nlme)
```

This is how a dataframe coudl look like: 

```{r}
n_reps <- 3
data <- 
  purrr::map_dfr(
    seq_len(n_reps),
    ~expand.grid(tA = factor(1:3),
                tB = factor(1:2)) |>
      mutate(mu = c(10,12,12,10,10,12))) |> 
  mutate(rep = rep(1:n_reps, each = 6))
head(data)

# Also:

sigma2_e <- 1
sigma2_block <- sigma2_block
sigma2_wp <- .2
```

How do different designs compare? 

```{r}
# create an RCBD model 
m_rcbd <- lme(mu ~ tA * tB, 
         random = list(rep = pdSymm(matrix(sqrt(sigma2_block)), ~ 1, nam = "(Intercept)")), 
         data = data,
         # this won't converge but ask to get an object anyways
         control = lmeControl(
           sigma = sqrt(sigma2_e),
           returnObject = TRUE))


# peek at the variance-covariance matrix 
VarCorr(m_rcbd)

# fix variance components 
m_rcbd$modelStruct$reStruct$rep <-  pdSymm(matrix(sqrt(sigma2_block)), ~ 1, nam = "(Intercept)")

# peek at the variance-covariance matrix again
VarCorr(m_rcbd)


results <-
  emmeans::joint_tests(m_rcbd) |> 
  as.data.frame() |> 
  transmute(source = `model term`, 
            numDF = df1, 
            denDF = df2, 
            F.ratio)

alpha <- 0.05

results |> 
  mutate(ncp = F.ratio* numDF, 
         Fcrit = qf(1-alpha, df1 = numDF, df2 = denDF, ncp = 0),
         Power = 1 - pf(Fcrit, df1 = numDF, df2 = denDF, ncp = ncp))
```


```{r}
# create a split-plot model where tA was the whole plot  
m_sp <- lme(mu ~ tA * tB, 
         random = list(rep = pdSymm(matrix(sqrt(sigma2_block)), ~ 1, 
                                    nam = "(Intercept)"), 
                       tA = pdSymm(matrix(sqrt(sigma2_wp)), ~ 1)), 
         data = data,
         # this won't converge but ask to get an object anyways
         control = lmeControl(sigma = sqrt(sigma2_e), 
                              returnObject = TRUE, 
                              maxIter = 0))

# peek at the variance-covariance matrix 
VarCorr(m_sp)

# fix variance components 
m_sp$modelStruct$reStruct$rep <-  pdSymm(matrix(sqrt(sigma2_block)), ~ 1, nam = "(Intercept)")
m_sp$modelStruct$reStruct$tA <-  pdSymm(matrix(sqrt(sigma2_wp)), ~ 1, nam = "(Intercept)")

# peek at the variance-covariance matrix again
VarCorr(m_sp)

results <-
  emmeans::joint_tests(m_sp) |> 
  as.data.frame() |> 
  transmute(source = `model term`, 
            numDF = df1, 
            denDF = df2, 
            F.ratio)

alpha <- 0.05

results |> 
  mutate(ncp = F.ratio* numDF, 
         Fcrit = qf(1-alpha, df1 = numDF, df2 = denDF, ncp = 0),
         Power = 1 - pf(Fcrit, df1 = numDF, df2 = denDF, ncp = ncp))
```


### Precision analysis 

- Power analysis versus precision analyses (the focus on p-values)  
- [ASA's statement on p-values](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)
- [Scientists rise up against statistical significance](https://www.nature.com/articles/d41586-019-00857-9) 
  - [Discussion](https://statmodeling.stat.columbia.edu/2019/03/20/retire-statistical-significance-the-discussion/) 
  - Counterargument: [In defense of p-values](https://esajournals.onlinelibrary.wiley.com/doi/10.1890/13-0590.1) 
- Gelman "Let us have the serenity to embrace the variation that we cannot reduce, the courage to reduce the variation we cannot embrace, and the wisdom to distinguish one from the other." [[see talk](https://www.youtube.com/watch?v=KS3yPw91iC0&t=3252s)] 


```{r}
res <- as.data.frame(emmeans::emmeans(m_rcbd, ~ tA, contr = list(c(1, -1, 0)))$contrasts)
res$SE*(qt(p = .975, df = res$df) - qt(p = .025, df = res$df))

res <- as.data.frame(emmeans::emmeans(m_sp, ~ tA, contr = list(c(1, -1, 0)))$contrasts)
res$SE*(qt(p = .975, df = res$df) - qt(p = .025, df = res$df))
```


## Bayesian analysis of designed experiments 

Bayes theorem: 

$$[\boldsymbol{\theta} \vert \mathbf{y}] = \frac{[\mathbf{y} \vert \boldsymbol{\theta}] [\boldsymbol{\theta}] }{ [\mathbf{y}]}, $$

where: 

- $[\boldsymbol{\theta} \vert \mathbf{y}]$ is the posterior distribution, 
- $[\mathbf{y} \vert \boldsymbol{\theta}]$ is the likelihood, 
- $[\boldsymbol{\theta}]$ is the prior, 
- $[\mathbf{y}]$ is the data. 

Note that whatever is defined in $[\cdot]$, it's information. 


## Applied example 

Suppose we designed an experiment with the rationale outlined above. What if the model doesn't converge?

- About dropping effects from the model 
- Bayesian solutions 

```{r message=FALSE, warning=FALSE}
library(glmmTMB)
library(ggpubr)
```

```{r}
dat <- readxl::read_xlsx("../../data_confid/Behavior_Counts.xlsx")

# viz
dat |> 
  ggplot(aes(timepoint, behavior_count))+
  geom_point(aes(group = breed, 
                 fill = breed),
             shape =21, size= 2.5)+
  facet_wrap(~trt)+
  scico::scale_fill_scico_d()+
  theme_pubclean()
```



```{r}
m2 <- glmmTMB(behavior_count ~ timepoint * trt * breed +
                toep(timepoint + 0 | calfID),
              ziformula = ~1,
              family = poisson(link = "log"),
              data = dat |> mutate(timepoint_f=as.factor(timepoint)))
```

What to do? 

[Link to Stan code](../scripts/12082025_stan_desexp.stan)

## Resources 

- [Stan website](https://mc-stan.org/) & [documentation](https://mc-stan.org/docs/) 
- [Download cmdstanr](https://mc-stan.org/cmdstanr/) 


